{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mN94ZBUG6B1c"
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1322,
     "status": "ok",
     "timestamp": 1631091813892,
     "user": {
      "displayName": "Haseeb Raja",
      "photoUrl": "",
      "userId": "05768657324933001500"
     },
     "user_tz": -540
    },
    "id": "qfu3RRC3SV5i",
    "outputId": "74394401-ff04-470d-c558-20656c179393"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = '../dataset/train/'\n",
    "TEST_DIR = '../dataset/test/'\n",
    "\n",
    "# Check hardware accelerator\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1631090937713,
     "user": {
      "displayName": "Haseeb Raja",
      "photoUrl": "",
      "userId": "05768657324933001500"
     },
     "user_tz": -540
    },
    "id": "-OP5ScZoSpfW",
    "outputId": "ab486cdb-e66c-464a-e799-1fc155e387dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes:  4\n",
      "Total train images:  7330\n",
      "Total test images:  34\n"
     ]
    }
   ],
   "source": [
    "### Exploring Dataset\n",
    "\n",
    "classes = os.listdir(TRAIN_DIR)\n",
    "print(\"Total Classes: \",len(classes))\n",
    "\n",
    "train_count = 0\n",
    "test_count = 0\n",
    "\n",
    "for _class in classes:\n",
    "    train_count += len(os.listdir(TRAIN_DIR + _class))\n",
    "    test_count += len(os.listdir(TEST_DIR + _class))\n",
    "    \n",
    "print(\"Total train images: \",train_count)\n",
    "print(\"Total test images: \",test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 402,
     "status": "ok",
     "timestamp": 1631090941972,
     "user": {
      "displayName": "Haseeb Raja",
      "photoUrl": "",
      "userId": "05768657324933001500"
     },
     "user_tz": -540
    },
    "id": "rQyb4JXyUXcF"
   },
   "outputs": [],
   "source": [
    "# Utility to apply transforms\n",
    "def get_transform():\n",
    "  mean = (127.5)\n",
    "  std = (127.5)\n",
    "  normalize = T.Normalize(mean=mean, std=std)\n",
    "  return T.Compose([normalize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8mpZdcOs9d2"
   },
   "source": [
    "# Loading Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 550,
     "status": "ok",
     "timestamp": 1629430696309,
     "user": {
      "displayName": "Haseeb Raja",
      "photoUrl": "",
      "userId": "05768657324933001500"
     },
     "user_tz": -540
    },
    "id": "pjbxncb6SuaV",
    "outputId": "620be663-e661-408a-bc90-e86d50a91de4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7330\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(TRAIN_DIR, transforms=get_transform())\n",
    "test_dataset = CustomDataset(TEST_DIR, transforms=get_transform())\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "71-hPkohUSu6"
   },
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(dataset = train_dataset, batch_size = 128, shuffle=True)\n",
    "test_data_loader = DataLoader(dataset = test_dataset, batch_size = 128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1629430742781,
     "user": {
      "displayName": "Haseeb Raja",
      "photoUrl": "",
      "userId": "05768657324933001500"
     },
     "user_tz": -540
    },
    "id": "c_qqdyQ_r7Pc",
    "outputId": "83f7ad0e-9171-41d8-f690-f6d4e471bb00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GHNrOLyDRHIk"
   },
   "outputs": [],
   "source": [
    "def set_device():\n",
    "  if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "  else:\n",
    "    dev = \"cpu\"\n",
    "  return torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists!\n"
     ]
    }
   ],
   "source": [
    "name = 'models'\n",
    "\n",
    "try:\n",
    "    os.makedirs(os.path.join(os.getcwd(), f'{name}'))\n",
    "except FileExistsError:\n",
    "    print(\"Directory already exists!\")\n",
    "    pass\n",
    "\n",
    "modelDir = os.path.join(os.getcwd(), f'{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjEAtFnotQWn"
   },
   "source": [
    "# Define Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "erH6NjJPVZ1M"
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs):\n",
    "  device = set_device()\n",
    "  train_loss = []\n",
    "  train_acc = []\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    print(\"Epoch number {}\".format(epoch + 1))\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    total = 0\n",
    "      \n",
    "    # Training\n",
    "    for data in train_data_loader:\n",
    "      images, labels = data\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      total += labels.size(0)\n",
    "      \n",
    "      #Reset Grads\n",
    "      optimizer.zero_grad()\n",
    "      \n",
    "      #Forward ->\n",
    "      outputs = model(images)\n",
    "\n",
    "      # pred\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "      \n",
    "      #Calculate Loss & Backward, Update Weights (Step)\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      running_loss += loss.item() \n",
    "      running_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_data_loader)\n",
    "    epoch_acc = 100.00 * running_correct / total\n",
    "\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_acc.append(epoch_acc)\n",
    "\n",
    "    print(\"  - Training dataset: Got %d out of %d images correctly (%.3f%%). \\nEpoch loss: %.3f\"\n",
    "        % (running_correct, total, epoch_acc, epoch_loss))\n",
    "\n",
    "    test_acc = evaluate_model(model, test_loader)\n",
    "      \n",
    "    end = time.time()\n",
    "\n",
    "    print(\"-  Epoch Time : {} \\n\".format(int(end-start)))\n",
    "\n",
    "  print('Finished')\n",
    "  return model, train_acc, train_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function\n",
    "def evaluate_model(model, test_loader):\n",
    "  model.eval()\n",
    "  predicted_correctly_on_epoch = 0\n",
    "  total = 0\n",
    "  best_acc = 0.0\n",
    "  acc = []\n",
    "  device = set_device()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for data in test_data_loader: \n",
    "      images, labels = data\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      total += labels.size(0)\n",
    "\n",
    "      outputs = model(images)\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "      predicted_correctly_on_epoch += (predicted == labels).sum().item()\n",
    "  \n",
    "  epoch_acc = 100.0 * predicted_correctly_on_epoch / total\n",
    "  acc.append(epoch_acc)\n",
    "\n",
    "  if epoch_acc > best_acc:\n",
    "    best_acc = epoch_acc\n",
    "    torch.save(model.state_dict(), os.path.join(modelDir, 'best_model.pth'))\n",
    "\n",
    "  print(\"  - Testing dataset: Got %d out of %d images correctly (%.3f%%)\"\n",
    "        % (predicted_correctly_on_epoch, total, epoch_acc))\n",
    "  \n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeaSq3-tED3_"
   },
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 512,
     "status": "ok",
     "timestamp": 1631090949665,
     "user": {
      "displayName": "Haseeb Raja",
      "photoUrl": "",
      "userId": "05768657324933001500"
     },
     "user_tz": -540
    },
    "id": "VPBOitscCbc1",
    "outputId": "23363196-f31f-49d8-9f0f-713eef78ebaa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# # for resnet\n",
    "# model = models.resnet18(pretrained=True)\n",
    "# num_features = model.fc.in_features\n",
    "# num_classes = 4\n",
    "# model.fc = nn.Linear(num_features, num_classes)\n",
    "# print(model)\n",
    "\n",
    "# for mobilenet\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "num_features = model.classifier[1].in_features\n",
    "num_classes = 4\n",
    "model.classifier[1] = nn.Linear(num_features, num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjEOFHXmI6G9"
   },
   "source": [
    "# Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DN6_CEXdIx6W"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32cuyFg9Jw6t"
   },
   "source": [
    "# Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 542052,
     "status": "ok",
     "timestamp": 1629431356173,
     "user": {
      "displayName": "Haseeb Raja",
      "photoUrl": "",
      "userId": "05768657324933001500"
     },
     "user_tz": -540
    },
    "id": "D3c4MhetJv2e",
    "outputId": "6e69fd4b-d0ee-46b8-d2a1-7fed9d8a8935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 1\n",
      "  - Training dataset: Got 4813 out of 7330 images correctly (65.662%). \n",
      "Epoch loss: 0.777\n",
      "  - Testing dataset: Got 16 out of 34 images correctly (47.059%)\n",
      "-  Epoch Time : 18 \n",
      "\n",
      "Epoch number 2\n",
      "  - Training dataset: Got 6644 out of 7330 images correctly (90.641%). \n",
      "Epoch loss: 0.277\n",
      "  - Testing dataset: Got 32 out of 34 images correctly (94.118%)\n",
      "-  Epoch Time : 18 \n",
      "\n",
      "Epoch number 3\n",
      "  - Training dataset: Got 7210 out of 7330 images correctly (98.363%). \n",
      "Epoch loss: 0.078\n",
      "  - Testing dataset: Got 32 out of 34 images correctly (94.118%)\n",
      "-  Epoch Time : 18 \n",
      "\n",
      "Epoch number 4\n",
      "  - Training dataset: Got 7289 out of 7330 images correctly (99.441%). \n",
      "Epoch loss: 0.032\n",
      "  - Testing dataset: Got 33 out of 34 images correctly (97.059%)\n",
      "-  Epoch Time : 17 \n",
      "\n",
      "Epoch number 5\n",
      "  - Training dataset: Got 7326 out of 7330 images correctly (99.945%). \n",
      "Epoch loss: 0.012\n",
      "  - Testing dataset: Got 33 out of 34 images correctly (97.059%)\n",
      "-  Epoch Time : 18 \n",
      "\n",
      "Epoch number 6\n",
      "  - Training dataset: Got 7329 out of 7330 images correctly (99.986%). \n",
      "Epoch loss: 0.006\n",
      "  - Testing dataset: Got 34 out of 34 images correctly (100.000%)\n",
      "-  Epoch Time : 18 \n",
      "\n",
      "Epoch number 7\n",
      "  - Training dataset: Got 7330 out of 7330 images correctly (100.000%). \n",
      "Epoch loss: 0.004\n",
      "  - Testing dataset: Got 34 out of 34 images correctly (100.000%)\n",
      "-  Epoch Time : 18 \n",
      "\n",
      "Epoch number 8\n",
      "  - Training dataset: Got 7330 out of 7330 images correctly (100.000%). \n",
      "Epoch loss: 0.003\n",
      "  - Testing dataset: Got 34 out of 34 images correctly (100.000%)\n",
      "-  Epoch Time : 18 \n",
      "\n",
      "Epoch number 9\n",
      "  - Training dataset: Got 7330 out of 7330 images correctly (100.000%). \n",
      "Epoch loss: 0.002\n",
      "  - Testing dataset: Got 34 out of 34 images correctly (100.000%)\n",
      "-  Epoch Time : 18 \n",
      "\n",
      "Epoch number 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25513/1892885909.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_LOSS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_ACC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST_ACC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_25513/2792968249.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m       \u001b[0mrunning_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_trained, TRAIN_LOSS, TRAIN_ACC, TEST_ACC = train_model(model, train_data_loader, test_data_loader, criterion, optimizer, lr_scheduler, num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model as well\n",
    "torch.save(model.state_dict(), os.path.join(modelDir, 'model.pth'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main_coreML.ipynb",
   "provenance": [
    {
     "file_id": "1dRi1Q8IhCiM5IaJXvoeXkib8kvi5JWk1",
     "timestamp": 1625548965810
    },
    {
     "file_id": "1kVTmE2wLyadRrfI3TERHU7OdZpXj_-Qy",
     "timestamp": 1625538153369
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
